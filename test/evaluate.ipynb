{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "dc1fc744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "058a5584",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "if \"../src\" not in sys.path:\n",
    "    sys.path.append(\"../src\")\n",
    "import settings\n",
    "import json\n",
    "from typing import List\n",
    "import utils\n",
    "import os\n",
    "\n",
    "from retriever import Retriever\n",
    "from reranker import Reranker\n",
    "from chatbot import Chatbot\n",
    "from langchain_openai import ChatOpenAI\n",
    "from rag_evaluator import RAGEvaluator\n",
    "\n",
    "logger = utils.get_logger(\"evaluate\")\n",
    "\n",
    "LOGS_DIR = \"logs/\"\n",
    "RESULTS_DIR = \"results/\"\n",
    "\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "06a3cd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_json(filename: str, obj: dict) -> None:\n",
    "    with open(filename, \"w\") as file:\n",
    "        json.dump(obj, file, indent=4, ensure_ascii=False, sort_keys=True)\n",
    "\n",
    "def load_json(filename) -> List[dict]:\n",
    "    with open(filename, \"r\") as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "def save_result(name: str, value: float):\n",
    "    with open(f\"{RESULTS_DIR}/{name}.json\", \"w\") as f:\n",
    "        json.dump({name: value}, f, indent=4)\n",
    "\n",
    "def get_chatbot_responses(chatbot: Chatbot, questions: List[str], rewrite_query: bool = False) -> List[dict]:\n",
    "    responses = []\n",
    "    for question in questions:\n",
    "        chatbot.run(query=question, rewrite_query=rewrite_query)\n",
    "        response = {\n",
    "            \"user_input\": question,\n",
    "            \"response\": chatbot.get_response(),\n",
    "            \"retrieved_contexts\": chatbot.get_context(),\n",
    "            \"retrieved_ids\": chatbot.get_documents_ids(),\n",
    "        }\n",
    "        responses.append(response)\n",
    "    return responses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a26027e",
   "metadata": {},
   "source": [
    "Load questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "a2ed1d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load questions\n",
    "questions = load_json(f\"data/questions.json\")\n",
    "sanity_check_questions = load_json(\"data/sanity_check_questions.json\")\n",
    "sanity_check_answers = load_json(\"data/sanity_check_answers.json\")\n",
    "question_mapping = {question: sanity_check_questions[i] for i, question in enumerate(questions)}\n",
    "answers_mapping = {question: sanity_check_answers[i] for i, question in enumerate(questions)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c800c913",
   "metadata": {},
   "source": [
    "#### Run chatbot with retriever only, save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "797e9291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retriever = Retriever(k=5)\n",
    "# reranker = Reranker()\n",
    "# chatbot_llm = ChatOpenAI(model=settings.OPENAI_MODEL, temperature=0.00000001, top_p=1)\n",
    "# chatbot = Chatbot(retriever=retriever, reranker=reranker, llm=chatbot_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "801023b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Run chatbot with retriever only\n",
    "# chatbot.rerank = False\n",
    "# responses = get_chatbot_responses(chatbot=chatbot, questions=questions)\n",
    "# save_json(f\"{LOGS_DIR}/qa_retriever.json\", responses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0779b70f",
   "metadata": {},
   "source": [
    "#### Run chatbot with reranker, save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "fe8ace24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retriever = Retriever(k=15)\n",
    "# reranker = Reranker()\n",
    "# chatbot_llm = ChatOpenAI(model=settings.OPENAI_MODEL, temperature=0.00000001, top_p=1)\n",
    "# chatbot = Chatbot(retriever=retriever, reranker=reranker, llm=chatbot_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "2d6a62c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Run chatbot with reranker\n",
    "# responses = get_chatbot_responses(chatbot=chatbot, questions=questions)\n",
    "# save_json(f\"{LOGS_DIR}/qa_reranker.json\", responses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389ee70a",
   "metadata": {},
   "source": [
    "### 1. Retriever evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "d9f484e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "evaluator = RAGEvaluator(k=k)\n",
    "data = load_json(f\"{LOGS_DIR}/qa_retriever.json\")\n",
    "evaluator.load_data(data)\n",
    "\n",
    "# initialize sanity check evaluator, uses different logs and results directories\n",
    "sanity_check_evaluator = RAGEvaluator(k=k)\n",
    "sanity_check_evaluator.logs_dir = os.path.join(settings.BASE_DIR, \"test\", \"logs\", \"sanity_check\")\n",
    "sanity_check_evaluator.results_dir = os.path.join(settings.BASE_DIR, \"test\", \"results\", \"sanity_check\")\n",
    "\n",
    "# load data: replace user queries with random, out of domain, sanity check questions\n",
    "sanity_check_data = load_json(f\"{LOGS_DIR}/qa_retriever.json\")\n",
    "for item in sanity_check_data:\n",
    "    item[\"user_input\"] = question_mapping[item[\"user_input\"]]\n",
    "sanity_check_evaluator.load_data(sanity_check_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07937e51",
   "metadata": {},
   "source": [
    "#### 1.1 Retriever MAP@k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "aec76e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever MAP@5: 0.7213\n"
     ]
    }
   ],
   "source": [
    "retriever_map_at_k = evaluator.compute_map_at_k()\n",
    "results[\"retriever_map_at_k\"] = retriever_map_at_k\n",
    "print(f\"Retriever MAP@{k}: {retriever_map_at_k:.4f}\")\n",
    "# save_result(f\"retriever_map_at_{k}\", retriever_map_at_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c977e02",
   "metadata": {},
   "source": [
    "Sanity check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "6e6a9540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity check retriever MAP@5: 0.0000\n"
     ]
    }
   ],
   "source": [
    "sanity_check_retriever_map_at_k = sanity_check_evaluator.compute_map_at_k()\n",
    "results[\"sanity_check_retriever_map_at_k\"] = sanity_check_retriever_map_at_k\n",
    "print(f\"Sanity check retriever MAP@{k}: {sanity_check_retriever_map_at_k:.4f}\")\n",
    "# save_result(f\"sanity_check_retriever_map_at_{k}\", sanity_check_retriever_map_at_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e8f1a4",
   "metadata": {},
   "source": [
    "#### 1.2 Retriever MRR@k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "65e74856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever MRR@5: 0.7354\n"
     ]
    }
   ],
   "source": [
    "retriever_mrr_at_k = evaluator.compute_mrr_at_k()\n",
    "results[\"retriever_mrr_at_k\"] = retriever_mrr_at_k\n",
    "print(f\"Retriever MRR@{k}: {retriever_mrr_at_k:.4f}\")\n",
    "# save_result(f\"retriever_mrr_at_{k}\", retriever_mrr_at_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64862acd",
   "metadata": {},
   "source": [
    "Sanity check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "11d9150a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity check Retriever MRR@5: 0.0000\n"
     ]
    }
   ],
   "source": [
    "sanity_check_retriever_mrr_at_k = sanity_check_evaluator.compute_mrr_at_k()\n",
    "results[\"sanity_check_retriever_mrr_at_k\"] = sanity_check_retriever_mrr_at_k\n",
    "print(f\"Sanity check Retriever MRR@{k}: {sanity_check_retriever_mrr_at_k:.4f}\")\n",
    "# save_result(f\"sanity_check_retriever_mrr_at_{k}\", sanity_check_retriever_mrr_at_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97189f6c",
   "metadata": {},
   "source": [
    "### 2. Reranker evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "8896211b",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "evaluator = RAGEvaluator(k=k)\n",
    "data = load_json(f\"{LOGS_DIR}/qa_reranker.json\")\n",
    "evaluator.load_data(data)\n",
    "\n",
    "# initialize sanity check evaluator, uses different logs and results directories\n",
    "sanity_check_evaluator = RAGEvaluator(k=k)\n",
    "sanity_check_evaluator.logs_dir = os.path.join(settings.BASE_DIR, \"test\", \"logs\", \"sanity_check\")\n",
    "sanity_check_evaluator.results_dir = os.path.join(settings.BASE_DIR, \"test\", \"results\", \"sanity_check\")\n",
    "\n",
    "# load data: replace user queries with random, out of domain, sanity check questions\n",
    "sanity_check_data = load_json(f\"{LOGS_DIR}/qa_reranker.json\")\n",
    "for item in sanity_check_data:\n",
    "    item[\"user_input\"] = question_mapping[item[\"user_input\"]]\n",
    "sanity_check_evaluator.load_data(sanity_check_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f7168b",
   "metadata": {},
   "source": [
    "#### 2.1 Reranker MAP@k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "061782c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranker MAP@5: 0.8292\n"
     ]
    }
   ],
   "source": [
    "reranker_map_at_k = evaluator.compute_map_at_k()\n",
    "results[\"reranker_map_at_k\"] = reranker_map_at_k\n",
    "print(f\"Reranker MAP@{k}: {reranker_map_at_k:.4f}\")\n",
    "# save_result(f\"reranker_map_at_{k}\", reranker_map_at_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f105967",
   "metadata": {},
   "source": [
    "Sanity check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "6b9da604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity check Reranker MAP@5: 0.0000\n"
     ]
    }
   ],
   "source": [
    "sanity_check_reranker_map_at_k = sanity_check_evaluator.compute_map_at_k()\n",
    "results[\"sanity_check_reranker_map_at_k\"] = sanity_check_reranker_map_at_k\n",
    "print(f\"Sanity check Reranker MAP@{k}: {sanity_check_reranker_map_at_k:.4f}\")\n",
    "# save_result(f\"sanity_check_reranker_map_at_{k}\", sanity_check_reranker_map_at_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eda9db1",
   "metadata": {},
   "source": [
    "#### 2.2 Reranker MRR@k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "613efa5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranker MRR@5: 0.8604\n"
     ]
    }
   ],
   "source": [
    "reranker_mrr_at_k = evaluator.compute_mrr_at_k()\n",
    "results[\"reranker_mrr_at_k\"] = reranker_mrr_at_k\n",
    "print(f\"Reranker MRR@{k}: {reranker_mrr_at_k:.4f}\")\n",
    "# save_result(f\"reranker_mrr_at_{k}\", reranker_mrr_at_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067f466a",
   "metadata": {},
   "source": [
    "Sanity check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "74b748eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity check Reranker MRR@5: 0.0000\n"
     ]
    }
   ],
   "source": [
    "sanity_check_reranker_mrr_at_k = sanity_check_evaluator.compute_mrr_at_k()\n",
    "results[\"sanity_check_reranker_mrr_at_k\"] = sanity_check_reranker_mrr_at_k\n",
    "print(f\"Sanity check Reranker MRR@{k}: {sanity_check_reranker_mrr_at_k:.4f}\")\n",
    "# save_result(f\"sanity_check_reranker_mrr_at_{k}\", sanity_check_reranker_mrr_at_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3144a7fc",
   "metadata": {},
   "source": [
    "### 3. End-to-end system evaluation\n",
    "Prompts translated and adapted from the [RAGAs paper](http://arxiv.org/abs/2309.15217)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468bd9ed",
   "metadata": {},
   "source": [
    "#### 3.1 GPT Score - Faithfulness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "af10bc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "evaluator = RAGEvaluator(k=k)\n",
    "data = load_json(f\"{LOGS_DIR}/qa_reranker.json\")\n",
    "evaluator.load_data(data)\n",
    "\n",
    "# initialize sanity check evaluator, uses different logs and results directories\n",
    "sanity_check_evaluator = RAGEvaluator(k=k)\n",
    "sanity_check_evaluator.logs_dir = os.path.join(settings.BASE_DIR, \"test\", \"logs\", \"sanity_check\")\n",
    "sanity_check_evaluator.results_dir = os.path.join(settings.BASE_DIR, \"test\", \"results\", \"sanity_check\")\n",
    "\n",
    "# load data: replace chatbot answers with random, out of domain, sanity check answers\n",
    "sanity_check_data = load_json(f\"{LOGS_DIR}/qa_reranker.json\")\n",
    "for item in sanity_check_data:\n",
    "    item[\"response\"] = answers_mapping[item[\"user_input\"]]\n",
    "sanity_check_evaluator.load_data(sanity_check_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "deb15852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Faithfulness GPT Score: 0.9450\n"
     ]
    }
   ],
   "source": [
    "faithfulness_gpt_score = evaluator.compute_faithfulness_gpt_score()\n",
    "results[\"faithfulness_gpt_score\"] = faithfulness_gpt_score\n",
    "print(f\"Faithfulness GPT Score: {faithfulness_gpt_score:.4f}\")\n",
    "# save_result(\"gptscore_faithfulness\", faithfulness_gpt_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb05169",
   "metadata": {},
   "source": [
    "Sanity check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "f1a649d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Check Faithfulness GPT Score: 0.0000\n"
     ]
    }
   ],
   "source": [
    "sanity_check_faithfulness_gpt_score = sanity_check_evaluator.compute_faithfulness_gpt_score()\n",
    "results[\"sanity_check_faithfulness_gpt_score\"] = sanity_check_faithfulness_gpt_score\n",
    "print(f\"Sanity Check Faithfulness GPT Score: {sanity_check_faithfulness_gpt_score:.4f}\")\n",
    "# save_result(\"sanity_check_gptscore_faithfulness\", sanity_check_faithfulness_gpt_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd0234b",
   "metadata": {},
   "source": [
    "#### 3.2 GPT Score - Answer relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "464a9997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer relevance GPT Score: 0.8125\n"
     ]
    }
   ],
   "source": [
    "answer_relevance_gpt_score = evaluator.compute_answer_relevance_gpt_score()\n",
    "results[\"answer_relevance_gpt_score\"] = answer_relevance_gpt_score\n",
    "print(f\"Answer relevance GPT Score: {answer_relevance_gpt_score:.4f}\")\n",
    "# save_result(\"gptscore_answer_relevance\", answer_relevance_gpt_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbeb0102",
   "metadata": {},
   "source": [
    "Sanity check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548c5d57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "16a27d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity check Answer relevance GPT Score: 0.0000\n"
     ]
    }
   ],
   "source": [
    "sanity_check_answer_relevance_gpt_score = sanity_check_evaluator.compute_answer_relevance_gpt_score()\n",
    "results[\"sanity_check_answer_relevance_gpt_score\"] = sanity_check_answer_relevance_gpt_score\n",
    "print(f\"Sanity check Answer relevance GPT Score: {sanity_check_answer_relevance_gpt_score:.4f}\")\n",
    "# save_result(\"sanity_check_gptscore_answer_relevance\", sanity_check_answer_relevance_gpt_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263af8a6",
   "metadata": {},
   "source": [
    "#### 3.3 RAGAs - Faithfulness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "cf537d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error saving prompts: The file '/home/ana/ACS/rag/test/prompts/faithfulness_n_l_i_statement_prompt_romanian.json' already exists.\n",
      "All entries already evaluated.\n",
      "Faithfulness RAGAs: 0.8155\n"
     ]
    }
   ],
   "source": [
    "faithfulness_ragas = await evaluator.compute_faithfulness_ragas()\n",
    "results[\"faithfulness_ragas\"] = faithfulness_ragas\n",
    "print(f\"Faithfulness RAGAs: {faithfulness_ragas:.4f}\")\n",
    "# save_result(\"ragas_faithfulness\", faithfulness_ragas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655697aa",
   "metadata": {},
   "source": [
    "Sanity check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "77781a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error saving prompts: The file '/home/ana/ACS/rag/test/prompts/faithfulness_n_l_i_statement_prompt_romanian.json' already exists.\n",
      "All entries already evaluated.\n",
      "Sanity check Faithfulness RAGAs: 0.0000\n"
     ]
    }
   ],
   "source": [
    "sanity_check_faithfulness_ragas = await sanity_check_evaluator.compute_faithfulness_ragas()\n",
    "results[\"sanity_check_faithfulness_ragas\"] = sanity_check_faithfulness_ragas\n",
    "print(f\"Sanity check Faithfulness RAGAs: {sanity_check_faithfulness_ragas:.4f}\")\n",
    "# save_result(\"sanity_check_ragas_faithfulness\", sanity_check_faithfulness_ragas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d6a05c",
   "metadata": {},
   "source": [
    "#### 3.4 RAGAs - Answer relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "a5efb1cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error saving prompts: The file '/home/ana/ACS/rag/test/prompts/answer_relevancy_response_relevance_prompt_romanian.json' already exists.\n",
      "All entries already evaluated.\n",
      "Answer relevance RAGAs: 0.6590\n"
     ]
    }
   ],
   "source": [
    "answer_relevance_ragas = await evaluator.compute_answer_relevance_ragas()\n",
    "results[\"answer_relevance_ragas\"] = answer_relevance_ragas\n",
    "print(f\"Answer relevance RAGAs: {answer_relevance_ragas:.4f}\")\n",
    "# save_result(\"ragas_answer_relevance\", answer_relevance_ragas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de5cec4",
   "metadata": {},
   "source": [
    "Sanity check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "59fd083e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error saving prompts: The file '/home/ana/ACS/rag/test/prompts/answer_relevancy_response_relevance_prompt_romanian.json' already exists.\n",
      "All entries already evaluated.\n",
      "Sanity check Answer relevance RAGAs: 0.1057\n"
     ]
    }
   ],
   "source": [
    "sanity_check_answer_relevance_ragas = await sanity_check_evaluator.compute_answer_relevance_ragas()\n",
    "results[\"sanity_check_answer_relevance_ragas\"] = sanity_check_answer_relevance_ragas\n",
    "print(f\"Sanity check Answer relevance RAGAs: {sanity_check_answer_relevance_ragas:.4f}\")\n",
    "# save_result(\"sanity_check_ragas_answer_relevance\", sanity_check_answer_relevance_ragas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "798d795e",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_json(f\"{RESULTS_DIR}/results.json\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532b2c67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
