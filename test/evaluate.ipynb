{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc1fc744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "058a5584",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "if \"../src\" not in sys.path:\n",
    "    sys.path.append(\"../src\")\n",
    "import settings\n",
    "import json\n",
    "from typing import List\n",
    "import utils\n",
    "\n",
    "from retriever import Retriever\n",
    "from reranker import Reranker\n",
    "from chatbot import Chatbot\n",
    "from langchain_openai import ChatOpenAI\n",
    "from rag_evaluator import RAGEvaluator\n",
    "\n",
    "logger = utils.get_logger(\"evaluate\")\n",
    "\n",
    "LOGS_DIR = \"logs/\"\n",
    "RESULTS_DIR = \"results/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "06a3cd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_json(filename: str, obj: dict) -> None:\n",
    "    with open(filename, \"w\") as file:\n",
    "        json.dump(obj, file, indent=4, ensure_ascii=False)\n",
    "\n",
    "def load_json(filename) -> List[dict]:\n",
    "    with open(filename, \"r\") as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "def save_result(name: str, value: float):\n",
    "    with open(f\"{RESULTS_DIR}/{name}.json\", \"w\") as f:\n",
    "        json.dump({name: value}, f, indent=4)\n",
    "\n",
    "def get_chatbot_responses(chatbot: Chatbot, questions: List[str], rewrite_query: bool = False) -> List[dict]:\n",
    "    responses = []\n",
    "    for question in questions:\n",
    "        chatbot.run(query=question, rewrite_query=rewrite_query)\n",
    "        response = {\n",
    "            \"user_input\": question,\n",
    "            \"response\": chatbot.get_response(),\n",
    "            \"retrieved_contexts\": chatbot.get_context(),\n",
    "            \"retrieved_ids\": chatbot.get_documents_ids(),\n",
    "        }\n",
    "        responses.append(response)\n",
    "    return responses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a26027e",
   "metadata": {},
   "source": [
    "Load questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a2ed1d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load questions\n",
    "questions = load_json(f\"data/questions.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c800c913",
   "metadata": {},
   "source": [
    "#### Run chatbot with retriever only, save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "797e9291",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = Retriever(k=5)\n",
    "reranker = Reranker()\n",
    "chatbot_llm = ChatOpenAI(model=settings.OPENAI_MODEL, temperature=0.00000001, top_p=1)\n",
    "chatbot = Chatbot(retriever=retriever, reranker=reranker, llm=chatbot_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801023b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run chatbot with retriever only\n",
    "chatbot.rerank = False\n",
    "responses = get_chatbot_responses(chatbot=chatbot, questions=questions)\n",
    "save_json(f\"{LOGS_DIR}/qa_retriever.json\", responses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0779b70f",
   "metadata": {},
   "source": [
    "#### Run chatbot with reranker, save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe8ace24",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = Retriever(k=15)\n",
    "reranker = Reranker()\n",
    "chatbot_llm = ChatOpenAI(model=settings.OPENAI_MODEL, temperature=0.00000001, top_p=1)\n",
    "chatbot = Chatbot(retriever=retriever, reranker=reranker, llm=chatbot_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2d6a62c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run chatbot with reranker\n",
    "responses = get_chatbot_responses(chatbot=chatbot, questions=questions)\n",
    "save_json(f\"{LOGS_DIR}/qa_reranker.json\", responses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389ee70a",
   "metadata": {},
   "source": [
    "### 1. Retriever evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d9f484e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "evaluator = RAGEvaluator(k=k)\n",
    "data = load_json(f\"{LOGS_DIR}/qa_retriever.json\")\n",
    "evaluator.load_data(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07937e51",
   "metadata": {},
   "source": [
    "#### 1.1 Retriever MAP@k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aec76e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever MAP@5: 0.7273\n"
     ]
    }
   ],
   "source": [
    "retriever_map_at_k = evaluator.compute_map_at_k()\n",
    "print(f\"Retriever MAP@{k}: {retriever_map_at_k:.4f}\")\n",
    "# save_result(f\"retriever_map_at_{k}\", retriever_map_at_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e8f1a4",
   "metadata": {},
   "source": [
    "#### 1.2 Retriever MRR@k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "65e74856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever MRR@5: 0.7149\n"
     ]
    }
   ],
   "source": [
    "retriever_mrr_at_k = evaluator.compute_mrr_at_k()\n",
    "print(f\"Retriever MRR@{k}: {retriever_mrr_at_k:.4f}\")\n",
    "# save_result(f\"retriever_mrr_at_{k}\", retriever_mrr_at_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97189f6c",
   "metadata": {},
   "source": [
    "### 2. Reranker evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8896211b",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "evaluator = RAGEvaluator(k=k)\n",
    "data = load_json(f\"{LOGS_DIR}/qa_reranker.json\")\n",
    "evaluator.load_data(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f7168b",
   "metadata": {},
   "source": [
    "#### 2.1 Reranker MAP@k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "061782c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranker MAP@5: 0.8094\n"
     ]
    }
   ],
   "source": [
    "reranker_map_at_k = evaluator.compute_map_at_k()\n",
    "print(f\"Reranker MAP@{k}: {reranker_map_at_k:.4f}\")\n",
    "# save_result(f\"reranker_map_at_{k}\", reranker_map_at_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eda9db1",
   "metadata": {},
   "source": [
    "#### 2.2 Reranker MRR@k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "613efa5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranker MRR@5: 0.8421\n"
     ]
    }
   ],
   "source": [
    "reranker_mrr_at_k = evaluator.compute_mrr_at_k()\n",
    "print(f\"Reranker MRR@{k}: {reranker_mrr_at_k:.4f}\")\n",
    "# save_result(f\"reranker_mrr_at_{k}\", reranker_mrr_at_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3144a7fc",
   "metadata": {},
   "source": [
    "### 3. End-to-end system evaluation\n",
    "Prompts translated and adapted from the [RAGAs paper](http://arxiv.org/abs/2309.15217)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468bd9ed",
   "metadata": {},
   "source": [
    "#### 3.1 GPT Score - Faithfulness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af10bc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "evaluator = RAGEvaluator(k=k)\n",
    "data = load_json(f\"{LOGS_DIR}/qa_reranker.json\")\n",
    "evaluator.load_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "deb15852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Faithfulness GPT Score: 0.9053\n"
     ]
    }
   ],
   "source": [
    "faithfulness_gpt_score = evaluator.compute_faithfulness_gpt_score()\n",
    "print(f\"Faithfulness GPT Score: {faithfulness_gpt_score:.4f}\")\n",
    "# save_result(\"gptscore_faithfulness\", faithfulness_gpt_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd0234b",
   "metadata": {},
   "source": [
    "#### 3.2 GPT Score - Answer relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "464a9997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer relevance GPT Score: 0.8579\n"
     ]
    }
   ],
   "source": [
    "answer_relevance_gpt_score = evaluator.compute_answer_relevance_gpt_score()\n",
    "print(f\"Answer relevance GPT Score: {answer_relevance_gpt_score:.4f}\")\n",
    "# save_result(\"gptscore_answer_relevance\", answer_relevance_gpt_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263af8a6",
   "metadata": {},
   "source": [
    "#### 3.3 RAGAs - Faithfulness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf537d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "faithfulness_ragas = await evaluator.compute_faithfulness_ragas()\n",
    "print(f\"Faithfulness RAGAs: {faithfulness_ragas:.4f}\")\n",
    "# save_result(\"ragas_faithfulness\", faithfulness_ragas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d6a05c",
   "metadata": {},
   "source": [
    "#### 3.4 RAGAs - Answer relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5efb1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_relevance_ragas = await evaluator.compute_answer_relevance_ragas()\n",
    "print(f\"Answer relevance RAGAs: {answer_relevance_ragas:.4f}\")\n",
    "# save_result(\"ragas_answer_relevance\", answer_relevance_ragas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fd083e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
